{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eff5ba8",
   "metadata": {},
   "source": [
    "# Creating a clean IMDB dataset\n",
    "\n",
    "Running this example requires `keras`. Use `pip install keras` to install if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53925437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a855c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe16fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0369a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 3 is for three terms: <START> <UNK> <UNUSED> \n",
    "num_words = 10000+3\n",
    "((S_train, Y_train), \n",
    " (S_test, Y_test)) = imdb.load_data(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e84d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.astype(np.float32)\n",
    "Y_test = Y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a737737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(sequences, ncol):\n",
    "    idx, vals = [], []\n",
    "    for i, s in enumerate(sequences):\n",
    "        idx.extend({(i,v):1 for v in s}.keys())\n",
    "    idx = np.array(idx).T\n",
    "    vals = np.ones(idx.shape[1], dtype=np.float32)\n",
    "    tens = torch.sparse_coo_tensor(indices=idx,\n",
    "                                   values=vals,\n",
    "                                   size=(len(sequences), ncol))\n",
    "    return tens.coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08ad327",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, L_train = one_hot(S_train, num_words), Y_train\n",
    "X_test = one_hot(S_test, num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98481bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_tensor(X):\n",
    "    idx = np.asarray(X.indices())\n",
    "    vals = np.asarray(X.values())\n",
    "    return coo_matrix((vals,\n",
    "                      (idx[0],\n",
    "                       idx[1])),\n",
    "                      shape=X.shape).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a17bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = convert_sparse_tensor(X_train)\n",
    "X_test_s = convert_sparse_tensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca57aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d = torch.tensor(X_train_s.todense())\n",
    "X_test_d = torch.tensor(X_test_s.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d017780",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_train_d, 'IMDB_X_train.tensor')\n",
    "torch.save(X_test_d, 'IMDB_X_test.tensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb0163",
   "metadata": {},
   "source": [
    "save the sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23afd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz('IMDB_X_test.npz', X_test_s)\n",
    "save_npz('IMDB_X_train.npz', X_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33568d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('IMDB_Y_test.npy', Y_test)\n",
    "np.save('IMDB_Y_train.npy', L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9110984",
   "metadata": {},
   "source": [
    "save and pickle the word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff44a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "lookup = {(i+3):w for w, i in word_index.items()}\n",
    "lookup[0] = \"<PAD>\"\n",
    "lookup[1] = \"<START>\"\n",
    "lookup[2] = \"<UNK>\"\n",
    "lookup[4] = \"<UNUSED>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1486c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lookup, open('IMDB_word_index.pkl', 'bw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e606c5",
   "metadata": {},
   "source": [
    "create the padded representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ab7a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(S_train,\n",
    " S_test) = [torch.tensor(pad_sequences(S, maxlen=500, value=0))\n",
    "            for S in [S_train,\n",
    "                      S_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55cb2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(S_train, 'IMDB_S_train.tensor')\n",
    "torch.save(S_test, 'IMDB_S_test.tensor')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb,md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "islp_test",
   "language": "python",
   "name": "islp_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
